%% Copyright (C) 2023 Alessandro Clerici Lorenzini
%
% This work may be distributed and/or modified under the
% conditions of the LaTeX Project Public License, either version 1.3
% of this license or (at your option) any later version.
% The latest version of this license is in
%   http://www.latex-project.org/lppl.txt
% and version 1.3 or later is part of all distributions of LaTeX
% version 2005/12/01 or later.
%
% This work has the LPPL maintenance status `maintained'.
%
% The Current Maintainer of this work is Alessandro Clerici Lorenzini
%
% This work consists of the files listed in work.txt


% TODO: sistemare un po'. Includere risultati sul tempo di esecuzione.
\section{Riduzione della probabilità di errore negli algoritmi bounded error}
\newcommand{\Balg}{\mathcal B}

Sia $\Aalg$ un algoritmo probabilistico bounded error per la funzione $F:I\to S$, la cui probabilità di errore è limitata da $\epsilon>0$.
Dato $\delta>0$, sia $k:=\ceil{\frac{1}{2\epsilon^2}\ln\frac{1}{\delta}}$ e sia $\Balg$ l'algoritmo che ripete $\Aalg$ $k$ volte e restituisce l'output che compare almeno $\ceil{\frac k2}$ volte o, se non esiste, dà in output $?$.

\begin{thm}
	La probabilità che $\Balg$ sbagli è al più $\delta$.
\end{thm}
\begin{proof}
	Per definizione di algoritmo bounded error si ha, per qualche $\epsilon>0$, $\Pr(\Aalg(x)=F(x))=:p\ge\frac 12+\epsilon$.
	La probabilità che $\Balg$ sbagli equivale alla probabilità che su $k$ esecuzioni di $\Aalg$ ci siano almeno $\ceil{\frac k2}$ insuccessi.
	Si può dunque modellare l'esecuzione di $\Balg$ con una binomiale di parametri $k$ e $p$. La probabilità che $\Balg$ sbagli è quindi quella che la variabile aleatoria binomiale $X_{kp}$ abbia valore minore di $\ceil{\frac k2}$:
	\begin{align*}
		\Pr(\text{errore}) & = \Pr(\Balg(x)\ne F(x))                  \\
		                   & = \Pr\left(X_{kp}<\ceil{\frac k2}\right) \\
		                   & = \Pr\left(X_{kp}<\frac k2\right)        \\
		                   & \le \Pr(X_{kp}<k(p-\epsilon))            \\
		                   & = \Pr(X_{kp}-kp<-k\epsilon)              \\
		                   & \le e^{-2\epsilon^2 k}
	\end{align*}
	L'ultima ottenuta applicando la disuguaglianza di Chernoff. Ponendo $e^{-2\epsilon^2 k}\le\delta$ si ricava
	\begin{equation*}
		k\ge\frac{1}{2\epsilon^2}\ln\frac{1}{\delta} \text. \qedhere
	\end{equation*}
\end{proof}
